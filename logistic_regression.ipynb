{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook we will go over what Logistic Regression is, and how to implement it in Python with [RAPIDS](https://medium.com/future-vision/what-is-rapids-ai-7e552d80a1d2?source=friends_link&sk=64b79c363beeffb9923e16482f3977cc) cuML.\n",
    "\n",
    "This Notebook can be run with a free GPU at [app.blazingsql.com](http://bit.ly/intro_ds_notebooks): `git clone https://github.com/Dropout-Analytics/cuml_logistic_regression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner's Guide to Logistic Regression with cuML\n",
    "\n",
    "Logistic regression is a model used for predicting the probability of events, given some other measurements. Logistic Regression is used when the dependent variable (\"target\") is categorical.\n",
    "\n",
    "For example,\n",
    "- Will the team win (1) or lose (0) this game?\n",
    "- Are users going to stop using our app (1) or not (0)?\n",
    "\n",
    "Logistic regression can also be used in non-binary situations, but let's cover that in a later post and stick to binary logistic regression for now.\n",
    "\n",
    "![Logistic Regression gif (University of Toronto)](https://cdn-images-1.medium.com/max/800/0*JgBI4I1QeTYQRj8j.gif)\n",
    "\n",
    "[Read more on Medium](https://medium.com/dropout-analytics/beginners-guide-to-logistic-regression-with-cuml-5061086d8694?source=friends_link&sk=2d8d0f7ddd43ccaaf264afcbadeea231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "df = cudf.read_csv('https://raw.githubusercontent.com/gumdropsteve/datasets/master/dog_or_horse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - What's the data look like?\n",
    "Before jumping in, let's explore our dataset. By converting cuDF `.to_pandas()`, we can utilize Matplotlib to visualize the overlaps in height and weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scatter dogs\n",
    "plt.scatter(df.loc[ df['target']==0 ]['weight'].to_pandas(), \n",
    "            y=df[ df['target']==0 ]['height'].to_pandas(), \n",
    "            label='dog', \n",
    "            color='#7400ff',\n",
    "            alpha=0.5)\n",
    "\n",
    "# scatter horses\n",
    "plt.scatter(df[ df['target']==1 ]['weight'].to_pandas(), \n",
    "            y=df[ df['target']==1 ]['height'].to_pandas(), \n",
    "            label='horse', \n",
    "            color='#36c9dd',\n",
    "            alpha=0.5)\n",
    "\n",
    "plt.legend(), plt.xlabel('Weight (lb)'), plt.ylabel('Height (in)'), plt.title('Horse or dog?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Height Histagram\n",
    "First let's plot just the heights, by using a histagram we can also see how the height of our samples from each animal are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histagram dog heights in purple \n",
    "plt.hist(df.loc[ df['target']==0 ]['height'].to_pandas(), label='dog', color='#7400ff', alpha=0.5)\n",
    "\n",
    "# histagram horse heights in teal\n",
    "plt.hist(df[ df['target']==1 ]['height'].to_pandas(), label='horse', color='#36c9dd', alpha=0.5)\n",
    "\n",
    "# add plot details\n",
    "plt.xlabel('height'), plt.ylabel('% population')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight Scatter Plot\n",
    "And now let's do something similar for weight. Since the distributions looked pretty uneven, let's focus in on their overlap when it comes to weight. We can do this by scattering the weights on the x-axis with a common y value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# scatter dog weights\n",
    "plt.scatter(df.loc[ df['target']==0 ]['weight'].to_pandas(), \n",
    "            y=np.zeros(df.loc[ df['target']==0 ]['weight'].shape), \n",
    "            label='dog', \n",
    "            color='#7400ff',\n",
    "            alpha=0.2)\n",
    "\n",
    "# scatter horse weights\n",
    "plt.scatter(df[ df['target']==1 ]['weight'].to_pandas(), \n",
    "            y=np.zeros(df.loc[ df['target']==1 ]['weight'].shape), \n",
    "            label='horse', \n",
    "            color='#36c9dd',\n",
    "            alpha=0.2)\n",
    "\n",
    "# add plot details\n",
    "plt.xlabel('weight'), plt.ylim([-0.25, 0.25])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Prep\n",
    "Using cuML's `train_test_split()` we can split our dataset into smaller training (`train`) and testing (`test`) datasets. This allows us to test our model with real data that it has never seen before. We'll drop the `type` column as the model will use `target` to differentiate between dogs and horses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.preprocessing import train_test_split\n",
    "\n",
    "df = df.drop('type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, 'target', train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200 rows (160/40), 3 columns (2/1(''))\n",
    "X_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with cuML\n",
    "\n",
    "![Dog rides her Horse](https://cdn-images-1.medium.com/max/800/0*ChQFw9yu7BD6Fz7g.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.linear_model.logistic_regression import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.fit()` the model to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(X_test)\n",
    "\n",
    "preds.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_test.copy()\n",
    "\n",
    "df['actual'] = y_test.values\n",
    "df['predicted'] = preds.values\n",
    "\n",
    "correct = df.loc[df['predicted']==df['actual']]\n",
    "n_correct = len(correct)\n",
    "\n",
    "print(f'{n_correct}/{len(df)} correct. \\n{n_correct / len(df)} accuracy. nice.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continued Learning\n",
    "Here are some resources to help fill in any gaps and provide a more complete understanding of Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSC 411: Lecture 04: Logistic Regression\n",
    "- University of Toronto: [04_prob_classif_handout.pdf](https://www.cs.toronto.edu/~urtasun/courses/CSC411_Fall16/04_prob_classif_handout.pdf)\n",
    "- by Richard Zemel, Raquel Urtasun and Sanja Fidler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression \n",
    "- Wikipedia: [wikipedia.org/wiki/Logistic_regression](https://wikipedia.org/wiki/Logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Videos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StatQuest: Logistic Regression\n",
    "- Watch on YouTube: https://youtu.be/yIYKR4sgzI8\n",
    "- Channel: StatQuest with Josh Starmer ([Subscribe](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw?sub_confirmation=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('yIYKR4sgzI8', width=(1280*0.667), height=(720*0.667))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture 6.1 — Logistic Regression | Classification — — [ Machine Learning | Andrew Ng]\n",
    "- Watch on YouTube: https://youtu.be/-la3q9d7AKQ\n",
    "- Channel:  Artificial Intelligence - All in One ([Subscribe](https://www.youtube.com/channel/UC5zx8Owijmv-bbhAK6Z9apg?sub_confirmation=1))\n",
    "  - **Note**: I'd recomend the [whole 6.x Lecture](https://www.youtube.com/playlist?list=PLNeKWBMsAzboR8vvhnlanxCNr2V7ITuxy) (6.1 - 6.7) if you want to understand the math behind logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('-la3q9d7AKQ', width=(854), height=(480))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPIDS Stable",
   "language": "python",
   "name": "rapids-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
